---
title: "Getting started"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
vignette: >
  %\VignetteIndexEntry{Getting started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  progress = FALSE,
  error = FALSE, message = FALSE
)

options(digits = 2)
```

## What is the RAKE algorithm?

The Rapid Automatic Keyword Extraction (RAKE) algorithm was first described in [Rose et al.](http://media.wiley.com/product_data/excerpt/22/04707498/0470749822.pdf) as a way to quickly extract keywords from documents. In short, the algorithm involves two steps:

**1. Identify candidate keywords.** A candidate keyword is any set of contiguous words (i.e., any n-gram) which doesn't contain a phrase delimiter or a stop word.[^1] A phrase delimiter is a punctuation character that marks the beginning or end of a phrase (e.g., a period or comma). Splitting up text based on phrase delimiters/stop words is the essential idea behind RAKE. According to the authors:

> RAKE is based on our observation that keywords frequently contain multiple words but rarely contain standard punctuation or stop words, such as the function words *and*, *the*, and *of*, or other words with minimal lexical meaning

In addition to using stop words and phrase delimiters to split text into keywords, you can also use a word's part-of-speech (POS). For example, most keywords don't contain verbs, so you may want to treat all verbs as if they are stop words. The original implementation of RAKE (as per Rose et al.) does not use a word's POS when creating the candidate keywords, but `slowrake()` gives you this option.  

**2. Calculate each keyword's score.** A keyword's score (i.e., its degree of "keywordness") is the sum of its member word scores. For example, the score for the keyword "dog leash" is calculated by adding the score for the word "dog" with the score for the word "leash." A word's score is equal to its degree/frequency, where degree is defined as the times that the word co-occurs with another word in a keyword, and frequency is just the total number of times that the keyword occurs overall.

See [Rose et al.](http://media.wiley.com/product_data/excerpt/22/04707498/0470749822.pdf) for more details on how RAKE works. 

## Examples

RAKE is unique in that it is completely unsupervised (i.e., no training data is required), so it's relatively easy to use. Let's take a look at a few basic examples that demonstrate `slowrake()`'s various parameters.

```{r}
library(slowraker)

txt <- "Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types of systems and systems of mixed types."
```

Use the default settings:
```{r}
slowrake(txt = txt)[[1]]
```

Don't stem the keywords before scoring them: 
```{r}
slowrake(txt = txt, stem = FALSE)[[1]]
```

Add the word "diophantine" to the default set of stop words (default set of stop words is `slowraker::smart_words`):
```{r}
slowrake(txt = txt, stop_words = c(smart_words, "diophantine"))[[1]]
```

Don't use a word's part-of-speech to determine if it's a stop word:
```{r}
slowrake(txt = txt, stop_pos = NULL)[[1]]
```

Consider words that aren't nouns to be stop words:
```{r}
slowrake(txt = txt, stop_pos = pos_tags$tag[!grepl("^N", pos_tags$tag)])[[1]]
```

List the keywords that occur most frequently (`freq`):
```{r}
res <- slowrake(txt = txt)[[1]]
res2 <- aggregate(freq ~ keyword + stem, data = res, FUN = sum)
res2[order(res2$freq, decreasing = TRUE), ]
```

Run RAKE on a vector of documents instead of just one document:
```{r}
slowrake(txt = dog_pubs$abstract[1:10])
```

## FAQs

### Why is it called *slow*raker?

`slowrake()` is written entirely in R, so it will probably be slower than the Java version of RAKE that I plan on writing in the near future (see the `rapidraker` R package for updates). You can speed up `slowrake()` by ignoring the words' part-of-speech (POS) when creating candidate keywords (i.e., set `stop_pos = NULL`).

### `slowrake()` is erroring from some memory issue (*OutOfMemoryError*). How can I fix this?

`slowrake()` relies on Java for POS tagging. Your Java virtual machine (JVM) may run out of memory during this process, thus causing the error. To fix this, try giving Java more memory:

```r
options(java.parameters = "-Xmx1024m")
```

To quote from [XLConnect](https://cran.r-project.org/web/packages/XLConnect/vignettes/XLConnect.pdf):

> [java.parameters] are evaluated exactly once per R session when the JVM is initialized - this is usually once you load the first package that uses Java support, so you should do this as early as possible. 

Also note that:

> The upper limit of the `Xmx` parameter is system dependent - most prominently, 32bit Windows will fail to work with anything much larger than 1500m, and it is usually a bad idea to set `Xmx` larger than your physical memory size because garbage collection and virtual memory do not play well together.

If changing `java.parameters` doesn't help, you can always tell `slowrake()` to skip POS tagging by setting `stop_pos` to `NULL`.

### Why do longer keywords (i.e., those that contain multiple words/tokens) always seem to have higher scores than shorter keywords?
 
Each keyword's score is found by summing up all of the scores of the words found inside it. For example, the score for the keyword "dog leash" is found by adding the score for the word "dog" with the score for the word "leash."

### Sometimes the part-of-speech tagging done by `slowrake()` appears to be incorrect. What can I do about this?

First, check if the tagging function used by `slowrake()` (`get_pos_tags()`) is indeed giving the wrong tags. To do that, try something like: `slowraker:::get_pos_tags(txt = "here is some text that I want tagged.")`. If the returned tags are indeed incorrect, try using a different tagger than the one used by `slowrake()`. Note, `get_pos_tags()` is basically a wrapper around the POS tagging functions found in the `openNLP` and `NLP` packages, so you'll want to look outside those packages for a different tagger.

[^1]: Technically, the original version of RAKE allows some keywords to contain stop words, but `slowrake()` does not allow for this.